{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd: Automatic Differentiation\n",
    "===================================\n",
    "\n",
    "Central to all neural networks in PyTorch is the ``autograd`` package.\n",
    "Let’s first briefly visit this, and we will then go to training our\n",
    "first neural network.\n",
    "\n",
    "\n",
    "The ``autograd`` package provides automatic differentiation for all operations\n",
    "on Tensors. It is a define-by-run framework, which means that your backprop is\n",
    "defined by how your code is run, and that every single iteration can be\n",
    "different.\n",
    "\n",
    "Let us see this in more simple terms with some examples.\n",
    "\n",
    "Tensor\n",
    "--------\n",
    "\n",
    "``torch.Tensor`` is the central class of the package. If you set its attribute\n",
    "``.requires_grad`` as ``True``, it starts to track all operations on it. When\n",
    "you finish your computation you can call ``.backward()`` and have all the\n",
    "gradients computed automatically. The gradient for this tensor will be\n",
    "accumulated into ``.grad`` attribute.\n",
    "\n",
    "To stop a tensor from tracking history, you can call ``.detach()`` to detach\n",
    "it from the computation history, and to prevent future computation from being\n",
    "tracked.\n",
    "\n",
    "To prevent tracking history (and using memory), you can also wrap the code block\n",
    "in ``with torch.no_grad():``. This can be particularly helpful when evaluating a\n",
    "model because the model may have trainable parameters with\n",
    "``requires_grad=True``, but for which we don't need the gradients.\n",
    "\n",
    "There’s one more class which is very important for autograd\n",
    "implementation - a ``Function``.\n",
    "\n",
    "``Tensor`` and ``Function`` are interconnected and build up an acyclic\n",
    "graph, that encodes a complete history of computation. Each tensor has\n",
    "a ``.grad_fn`` attribute that references a ``Function`` that has created\n",
    "the ``Tensor`` (except for Tensors created by the user - their\n",
    "``grad_fn is None``).\n",
    "\n",
    "If you want to compute the derivatives, you can call ``.backward()`` on\n",
    "a ``Tensor``. If ``Tensor`` is a scalar (i.e. it holds a one element\n",
    "data), you don’t need to specify any arguments to ``backward()``,\n",
    "however if it has more elements, you need to specify a ``gradient``\n",
    "argument that is a tensor of matching shape.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
    "flag in-place. The input flag defaults to ``False`` if not given.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x7f8cc1370278>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We dont need to specify requires_grad = False, since by default it flags it as False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.Tensor([[1, 2, 3], \n",
    "                       [4, 5, 6]])\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2 = torch.Tensor([[7, 8, 9], \n",
    "                        [10, 11, 12]])\n",
    "\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The requires_grad property defines whether to track operations on this tensor\n",
    "By default, it is set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The requires\\_grad\\_() function sets requires_grad to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], requires_grad=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The .grad property stores all the gradients for the tensor\n",
    "However, there are no gradients yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The .grad_fn property contains the gradient function\n",
    "This has not been set either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new output tensor from our original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = tensor1 * tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The requires_grad property has been derived from the original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are still no gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But there is a gradient function\n",
    "This is from the multiplication operation performed on the original tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x113472ac8>\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The original tensor still does not have a gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor2.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the operation for the output changes the gradient function\n",
    "The gradient function only contains the last operation. Here, even though there is a multiplication as well as a mean, only the mean calculation is recorded as the gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MeanBackward1 object at 0x113472c50>\n"
     ]
    }
   ],
   "source": [
    "output_tensor = (tensor1 * tensor2).mean()\n",
    "print(output_tensor.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In spite of setting a gradient function for the output, the gradients for the input tensor is still empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To calculate the gradients, we need to explicitly perform a backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradients are now available for the input tensor\n",
    "\n",
    "Future calls to backward will accumulate gradients into this vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1667, 1.3333, 1.5000],\n",
      "        [1.6667, 1.8333, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradient vector is the same shape as the original vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.grad.shape, tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The requires_grad property propagates to other tensors\n",
    "Here the new_tensor is created from the original tensor and gets the original's value of requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "new_tensor = tensor1 * 3\n",
    "print(new_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  6.,  9.],\n",
       "        [12., 15., 18.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turning off gradient calculations for tensors\n",
    "You can also stops autograd from tracking history on newly created tensors with requires_grad=True by wrapping the code block in <br />\n",
    "<b>with torch.no_grad():</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_tensor =  tensor([[ 3.,  6.,  9.],\n",
      "        [12., 15., 18.]])\n",
      "requires_grad for tensor =  True\n",
      "requires_grad for tensor =  False\n",
      "requires_grad for new_tensor =  False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    new_tensor = tensor1 * 3\n",
    "    \n",
    "    print('new_tensor = ', new_tensor)\n",
    "    \n",
    "    print('requires_grad for tensor = ', tensor1.requires_grad)\n",
    "    \n",
    "    print('requires_grad for tensor = ', tensor2.requires_grad)\n",
    "    \n",
    "    print('requires_grad for new_tensor = ', new_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can turn off gradient calculations performed within a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(t):\n",
    "    return t * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calculate_with_no_grad(t):\n",
    "    return t * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor = calculate(tensor1)\n",
    "\n",
    "result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor_no_grad = calculate_with_no_grad(tensor1)\n",
    "\n",
    "result_tensor_no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor_no_grad.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can explicitly enabled gradients within a no_grad() context\n",
    "\n",
    "There is an equivalent @torch.enable_grad() as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_tensor_no_grad =  tensor([[ 3.,  6.,  9.],\n",
      "        [12., 15., 18.]])\n",
      "new_tensor_grad =  tensor([[ 3.,  6.,  9.],\n",
      "        [12., 15., 18.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    new_tensor_no_grad = tensor1 * 3\n",
    "    \n",
    "    print('new_tensor_no_grad = ', new_tensor_no_grad)\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        \n",
    "        new_tensor_grad = tensor1 * 3\n",
    "    \n",
    "        print('new_tensor_grad = ', new_tensor_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result tensors get requires_grad properties from input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], requires_grad=True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_one = torch.tensor([[1.0, 2.0], \n",
    "                           [3.0, 4.0]], requires_grad=True)  \n",
    "tensor_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_two = torch.Tensor([[5, 6], \n",
    "                           [7, 8]])\n",
    "tensor_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### enable the gradients for  two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_one.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]], requires_grad=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_two.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tensor = (tensor_one + tensor_two).mean()\n",
    "final_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### final tensor has gradients enabled as it derives from the tensors its made up of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor_one.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tensor_two.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tensor.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_one.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_two.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(final_tensor.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detach tensors from the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detached_tensor = tensor_one.detach()\n",
    "\n",
    "detached_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], requires_grad=True)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tensor = (tensor_one + detached_tensor).mean()\n",
    "\n",
    "mean_tensor.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create a Variable with Float tensor\n",
    "\n",
    "The return value is not a variable instead it is a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = Variable(torch.FloatTensor([9]))\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create two weight variables with gradients enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Variable(torch.FloatTensor([3]), requires_grad = True)\n",
    "w2 = Variable(torch.FloatTensor([7]), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.], requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.], requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create two more variables using the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_var = var * w1\n",
    "\n",
    "result_var "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New variables derive enabled gradients from weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_var.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_var.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients\n",
    "---------\n",
    "Let's backprop now.\n",
    "Because ``out`` contains a single scalar, ``out.backward()`` is\n",
    "equivalent to ``out.backward(torch.tensor(1.))``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor and set ``requires_grad=True`` to track computation with it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a tensor operation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``y`` was created as a result of an operation, so it has a ``grad_fn``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f8d20f554a8>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do more operations on ``y``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print gradients d(out)/dx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have got a matrix of ``4.5``. Let’s call the ``out``\n",
    "*Tensor* “$o$”.\n",
    "We have that $o = \\frac{1}{4}\\sum_i z_i$,\n",
    "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
    "Therefore,\n",
    "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, hence\n",
    "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
    "\n",
    "Mathematically, if you have a vector valued function $\\vec{y}=f(\\vec{x})$,\n",
    "then the gradient of $\\vec{y}$ with respect to $\\vec{x}$\n",
    "is a Jacobian matrix:\n",
    "\n",
    "\\begin{align}J=\\left(\\begin{array}{ccc}\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
    "   \\vdots & \\ddots & \\vdots\\\\\n",
    "   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\\end{align}\n",
    "\n",
    "Generally speaking, ``torch.autograd`` is an engine for computing\n",
    "vector-Jacobian product. That is, given any vector\n",
    "$v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T}$,\n",
    "compute the product $v^{T}\\cdot J$. If $v$ happens to be\n",
    "the gradient of a scalar function $l=g\\left(\\vec{y}\\right)$,\n",
    "that is,\n",
    "$v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}$,\n",
    "then by the chain rule, the vector-Jacobian product would be the\n",
    "gradient of $l$ with respect to $\\vec{x}$:\n",
    "\n",
    "\\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc}\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
    "   \\vdots & \\ddots & \\vdots\\\\\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\\left(\\begin{array}{c}\n",
    "   \\frac{\\partial l}{\\partial y_{1}}\\\\\n",
    "   \\vdots\\\\\n",
    "   \\frac{\\partial l}{\\partial y_{m}}\n",
    "   \\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "   \\frac{\\partial l}{\\partial x_{1}}\\\\\n",
    "   \\vdots\\\\\n",
    "   \\frac{\\partial l}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\\end{align}\n",
    "\n",
    "(Note that $v^{T}\\cdot J$ gives a row vector which can be\n",
    "treated as a column vector by taking $J^{T}\\cdot v$.)\n",
    "\n",
    "This characteristic of vector-Jacobian product makes it very\n",
    "convenient to feed external gradients into a model that has\n",
    "non-scalar output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at an example of vector-Jacobian product:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 233.6886, 1184.6876, -514.4736], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in this case ``y`` is no longer a scalar. ``torch.autograd``\n",
    "could not compute the full Jacobian directly, but if we just\n",
    "want the vector-Jacobian product, simply pass the vector to\n",
    "``backward`` as argument:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also stop autograd from tracking history on Tensors\n",
    "with ``.requires_grad=True`` by wrapping the code block in\n",
    "``with torch.no_grad():``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Later:**\n",
    "\n",
    "Documentation of ``autograd`` and ``Function`` is at\n",
    "https://pytorch.org/docs/autograd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "<img src=\"linreg1.jpg\">\n",
    "<img src=\"linreg2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dataset\n",
    "A simple dataset using numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array ([[4.7], [2.4], [7.5], [7.1], [4.3], [7.816], \n",
    "                     [8.9], [5.2], [8.59], [2.1], [8] , \n",
    "                     [10], [4.5], [6], [4]],\n",
    "                    dtype = np.float32)\n",
    "\n",
    "y_train = np.array ([[2.6], [1.6], [3.09], [2.4], [2.4], [3.357], \n",
    "                     [2.6], [1.96], [3.53], [1.76], [3.2] , \n",
    "                     [3.5], [1.6], [2.5], [2.2]], \n",
    "                    dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the data\n",
    "There seems to be some relationship which can be plotted between x_train and y_train. A regression line can be drawn to represent the relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(x_train, y_train, label='Original data', s=250, c='g')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting data to pytorch tensors\n",
    "By defualt requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad for X_train:  False\n",
      "requires_grad for Y_train:  False\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(x_train) \n",
    "Y_train = torch.from_numpy(y_train)\n",
    "\n",
    "print('requires_grad for X_train: ', X_train.requires_grad)\n",
    "print('requires_grad for Y_train: ', Y_train.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the details for our neural network\n",
    "Input, output and hidden layer sizes plus the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1 \n",
    "hidden_size = 1\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create random Tensors for weights.<br>\n",
    "Setting requires_grad=True indicates that we want to compute gradients with respect to these Tensors during the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.rand(input_size, \n",
    "                hidden_size, \n",
    "                \n",
    "                requires_grad=True)\n",
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = torch.rand(hidden_size, \n",
    "                output_size, \n",
    "                \n",
    "                requires_grad=True)\n",
    "w2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "#### Foward Pass:\n",
    "* Predicting Y with input data X\n",
    "* finding (matrix X matrix) using .mm function, finding product of X_train and w1 and activation function is identity function\n",
    "* again doing mat product data with second weight w2\n",
    "\n",
    "#### Finding Loss:\n",
    "* Finding difference between Y_train and Y_pred by squaring the difference and then summing out, similar to nn.MSELoss \n",
    "\n",
    "\n",
    "#### For the loss_backward() function call:\n",
    "* backward pass will compute the gradient of loss with respect to all Tensors with requires_grad=True. \n",
    "* After this call w1.grad and w2.grad will be Tensors holding the gradient of the loss with respect to w1 and w2 respectively.\n",
    "\n",
    "#### Manually updating the weights\n",
    "* weights have requires_grad=True, but we don't need to track this in autograd. So will wrap it in torch.no_grad\n",
    "* reducing weight with multiple of learning rate and gradient\n",
    "* manually zero the weight gradients after updating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 34.43769836425781\n",
      "100 33.07548904418945\n",
      "150 31.73954963684082\n",
      "200 30.431819915771484\n",
      "250 29.154155731201172\n",
      "300 27.908218383789062\n",
      "350 26.695547103881836\n",
      "400 25.51750373840332\n",
      "450 24.375211715698242\n",
      "500 23.269697189331055\n",
      "550 22.201786041259766\n",
      "600 21.172130584716797\n",
      "650 20.181175231933594\n",
      "700 19.229232788085938\n",
      "750 18.316429138183594\n",
      "800 17.442710876464844\n",
      "850 16.607912063598633\n",
      "900 15.811686515808105\n",
      "950 15.053565979003906\n",
      "1000 14.332944869995117\n",
      "1050 13.649113655090332\n",
      "1100 13.001259803771973\n",
      "1150 12.388480186462402\n",
      "1200 11.809785842895508\n",
      "1250 11.264132499694824\n",
      "1300 10.750406265258789\n",
      "1350 10.267459869384766\n",
      "1400 9.814081192016602\n",
      "1450 9.389069557189941\n",
      "1500 8.99120044708252\n",
      "1550 8.619240760803223\n",
      "1600 8.271931648254395\n",
      "1650 7.948070049285889\n",
      "1700 7.646429538726807\n",
      "1750 7.365825176239014\n",
      "1800 7.105081558227539\n",
      "1850 6.863051891326904\n",
      "1900 6.6386518478393555\n",
      "1950 6.430819988250732\n",
      "2000 6.238509178161621\n",
      "2050 6.060738563537598\n",
      "2100 5.896563529968262\n",
      "2150 5.745084285736084\n",
      "2200 5.605425834655762\n",
      "2250 5.476797103881836\n",
      "2300 5.358409881591797\n",
      "2350 5.249531269073486\n",
      "2400 5.149483680725098\n",
      "2450 5.057603359222412\n",
      "2500 4.9732890129089355\n",
      "2550 4.895966053009033\n",
      "2600 4.825101852416992\n",
      "2650 4.760196685791016\n",
      "2700 4.700784683227539\n",
      "2750 4.646428108215332\n",
      "2800 4.596723556518555\n",
      "2850 4.551302433013916\n",
      "2900 4.5098114013671875\n",
      "2950 4.471930027008057\n"
     ]
    }
   ],
   "source": [
    "# Start at 10. Change this to 100, 1000 and 3000 and run the code all the way to the plot at the bottom\n",
    "for iter in range(1, 3000):\n",
    "    \n",
    "    y_pred = X_train.mm(w1).mm(w2)\n",
    "    loss = (y_pred - Y_train).pow(2).sum()\n",
    "    \n",
    "    if iter % 50 ==0:\n",
    "        print(iter, loss.item())\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:  tensor([[0.6014]], requires_grad=True)\n",
      "w2:  tensor([[0.6206]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print ('w1: ', w1)\n",
    "print ('w2: ', w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting data into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.7000],\n",
       "        [ 2.4000],\n",
       "        [ 7.5000],\n",
       "        [ 7.1000],\n",
       "        [ 4.3000],\n",
       "        [ 7.8160],\n",
       "        [ 8.9000],\n",
       "        [ 5.2000],\n",
       "        [ 8.5900],\n",
       "        [ 2.1000],\n",
       "        [ 8.0000],\n",
       "        [10.0000],\n",
       "        [ 4.5000],\n",
       "        [ 6.0000],\n",
       "        [ 4.0000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor = torch.from_numpy(x_train)\n",
    "x_train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the predicted values using the weights \n",
    "Using final weights calculated from our training in order to get the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7542],\n",
       "        [0.8957],\n",
       "        [2.7992],\n",
       "        [2.6499],\n",
       "        [1.6049],\n",
       "        [2.9172],\n",
       "        [3.3217],\n",
       "        [1.9408],\n",
       "        [3.2060],\n",
       "        [0.7838],\n",
       "        [2.9858],\n",
       "        [3.7323],\n",
       "        [1.6795],\n",
       "        [2.2394],\n",
       "        [1.4929]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_in_tensor = x_train_tensor.mm(w1).mm(w2)\n",
    "predicted_in_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the prediction to a numpy array\n",
    "This will be used to plot the regression line in a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.754175 ],\n",
       "       [0.895749 ],\n",
       "       [2.7992156],\n",
       "       [2.6499238],\n",
       "       [1.6048837],\n",
       "       [2.917156 ],\n",
       "       [3.3217356],\n",
       "       [1.9407895],\n",
       "       [3.206035 ],\n",
       "       [0.7837803],\n",
       "       [2.9858298],\n",
       "       [3.7322874],\n",
       "       [1.6795293],\n",
       "       [2.2393725],\n",
       "       [1.4929149]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = predicted_in_tensor.detach().numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting\n",
    "Our training has produced a rather accurate regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(x_train, y_train, label = 'Original data', s=250, c='g') \n",
    "\n",
    "plt.plot(x_train, predicted, label = 'Fitted line ')\n",
    "\n",
    "plt.legend() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "n=50\n",
    "x=np.random.rand(n)\n",
    "y=x*np.random.randn(n)\n",
    "\n",
    "colors = np.random.rand(n)\n",
    "plt.plot(np.unique(x),np.poly1d(np.polyfit(x,y,1))(np.unique(x)))\n",
    "\n",
    "plt.scatter(x,y,c=colors,alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 303.90716552734375\n",
      "100 1.977307206857404e-12\n",
      "w_alpha Grad =  -4.4405460357666016e-06  w_beta Grad =  -1.1502548886710429e-06\n",
      "200 1.977307206857404e-12\n",
      "w_alpha Grad =  -4.4405460357666016e-06  w_beta Grad =  -1.1502548886710429e-06\n",
      "300 1.977307206857404e-12\n",
      "w_alpha Grad =  -4.4405460357666016e-06  w_beta Grad =  -1.1502548886710429e-06\n",
      "400 1.977307206857404e-12\n",
      "w_alpha Grad =  -4.4405460357666016e-06  w_beta Grad =  -1.1502548886710429e-06\n",
      "500 1.977307206857404e-12\n",
      "w_alpha Grad =  -4.4405460357666016e-06  w_beta Grad =  -1.1502548886710429e-06\n",
      "600 1.977307206857404e-12\n",
      "w_alpha Grad =  -4.4405460357666016e-06  w_beta Grad =  -1.1502548886710429e-06\n",
      "700 1.977307206857404e-12\n",
      "w_alpha Grad =  -4.4405460357666016e-06  w_beta Grad =  -1.1502548886710429e-06\n",
      "800 1.977307206857404e-12\n",
      "w_alpha Grad =  -4.4405460357666016e-06  w_beta Grad =  -1.1502548886710429e-06\n",
      "900 1.977307206857404e-12\n",
      "w_alpha Grad =  -4.4405460357666016e-06  w_beta Grad =  -1.1502548886710429e-06\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "N = 64\n",
    "\n",
    "alpha = 1.3\n",
    "beta = np.array([[1.9],[1.5]])#\n",
    "\n",
    "x_data = np.random.randn(N, 2)#\n",
    "y_data = x_data.dot(beta) + alpha\n",
    "\n",
    "x=torch.from_numpy(x_data).float()\n",
    "y=torch.from_numpy(y_data).float()\n",
    "\n",
    "w_beta = torch.randn((2, 1), requires_grad=True)\n",
    "w_alpha = torch.randn(1, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD([w_beta, w_alpha], lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "for t in range(1000):\n",
    "    y_pred = x.mm(w_beta).add(w_alpha)\n",
    "    \n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "#     loss = criterion(y_pred,y)\n",
    "\n",
    "    if t % 100 == 0:\n",
    "        print(t, loss.item())\n",
    "        if w_alpha.grad is not None and w_beta.grad is not None:\n",
    "            print(\"w_alpha Grad = \",w_alpha.grad[0].item(),\" w_beta Grad = \",w_beta.grad[0].item())\n",
    "    \n",
    "    optimizer.zero_grad()   \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Beta: tensor([[1.9000],\n",
      "        [1.5000]], requires_grad=True)\n",
      "Optimized Alpha: tensor([1.3000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimized Beta: {0}\".format(w_beta))\n",
    "print(\"Optimized Alpha: {0}\".format(w_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.006211280822754\n",
      "500 0.004818673711270094\n",
      "1000 0.0013969732681289315\n",
      "1500 0.0002295930898981169\n",
      "2000 1.8603743228595704e-05\n",
      "2500 6.29012333774881e-07\n",
      "3000 7.020580117256259e-09\n",
      "3500 2.2144491101938613e-11\n",
      "4000 1.5726727212173053e-11\n",
      "4500 8.915463853287342e-12\n",
      "Optimized Alpha:  2.9999921321868896\n",
      "Optimized Beta:  1.0000044107437134\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "SIZE=100\n",
    "torch.manual_seed(123)\n",
    "\n",
    "class DS:\n",
    "    def __init__(self,size=SIZE):\n",
    "        self.x=torch.rand(size,1)\n",
    "        self.y=torch.Tensor(size,1)\n",
    "dataset=DS()\n",
    "\n",
    "for i in range(SIZE):\n",
    "    dataset.y[i,0]=3*dataset.x[i,0]+1\n",
    "\n",
    "\n",
    "x = dataset.x\n",
    "y = dataset.y\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.lin= torch.nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model=Model()\n",
    "lr = 0.01\n",
    "loss_func=torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "for t in range(5000):\n",
    "    y_pred=model(x)\n",
    "\n",
    "    loss=loss_func(y_pred,y)\n",
    "\n",
    "    if t % 500 == 0:\n",
    "        print(t, loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "print(\"Optimized Alpha: \",model.lin.weight[0].item())\n",
    "print(\"Optimized Beta: \",model.lin.bias[0].item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logestic Regression\n",
    "<img src=\"logreg1.jpg\">\n",
    "<img src=\"logreg2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Dataset\n",
      "[Parameter containing:\n",
      "tensor([[-0.1968,  0.0459],\n",
      "        [ 0.2205, -0.2500]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5479,  0.0048], requires_grad=True)]\n",
      "New Dataset\n",
      "('Step=', 0, ' Loss=', 0.6901295185089111, ' Acc=', 56.0)\n",
      "('Step=', 1000, ' Loss=', 0.15912514925003052, ' Acc=', 97.0)\n",
      "('Step=', 2000, ' Loss=', 0.10199522227048874, ' Acc=', 99.0)\n",
      "('Step=', 3000, ' Loss=', 0.076048843562603, ' Acc=', 99.0)\n",
      "('Step=', 4000, ' Loss=', 0.06001462787389755, ' Acc=', 99.0)\n",
      "('Step=', 5000, ' Loss=', 0.048503197729587555, ' Acc=', 100.0)\n",
      "('Step=', 6000, ' Loss=', 0.039517227560281754, ' Acc=', 100.0)\n",
      "('Step=', 7000, ' Loss=', 0.03216337785124779, ' Acc=', 100.0)\n",
      "('Step=', 8000, ' Loss=', 0.02601211704313755, ' Acc=', 100.0)\n",
      "('Step=', 9000, ' Loss=', 0.02085680328309536, ' Acc=', 100.0)\n",
      "()\n",
      "('Optimized Alpha: ', Parameter containing:\n",
      "tensor([[-37.1550, -36.4250],\n",
      "        [ 37.1772,  36.2191]], requires_grad=True))\n",
      "('Optimized Beta: ', Parameter containing:\n",
      "tensor([ 36.2542, -36.7982], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "SIZE = 100\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "class DS:\n",
    "    def __init__(self, size=SIZE):\n",
    "        self.x = torch.rand(size, 2)\n",
    "        self.y = torch.LongTensor(size)\n",
    "        print(\"New Dataset\")\n",
    "        for i in range(SIZE):\n",
    "            if (torch.sum(self.x[i]) > 1):\n",
    "                self.y[i] = 1\n",
    "            else:\n",
    "                self.y[i] = 0\n",
    "\n",
    "\n",
    "dataset = DS()\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lin = torch.nn.Linear(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "model = Model()\n",
    "print(list(model.parameters()))\n",
    "lr = 0.01\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "for t in range(10000):\n",
    "    if t % 10000 == 0:\n",
    "        dataset = DS()\n",
    "    y_pred = model(dataset.x)\n",
    "\n",
    "    loss = loss_func(y_pred, dataset.y)\n",
    "    \n",
    "    \n",
    "    if t % 1000 == 0:\n",
    "        _, pred = torch.max(y_pred, 1)\n",
    "\n",
    "        predTmp = pred.type(torch.FloatTensor).clone()\n",
    "        yTmp = dataset.y.float().clone()\n",
    "        # print(predTmp)\n",
    "        # print(yTmp)\n",
    "        acc = ((predTmp.data == yTmp).sum().float() / float(len(yTmp))) * 100.\n",
    "        print(\"Step=\",t,\" Loss=\", loss.item(), \" Acc=\", acc.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print()\n",
    "print(\"Optimized Alpha: \", model.lin.weight)\n",
    "print(\"Optimized Beta: \", model.lin.bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch MNIST Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import random as rand\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    avDev = torch.device(\"cuda\")\n",
    "else:\n",
    "    avDev = torch.device(\"cpu\")\n",
    "\n",
    "print(avDev)\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    " \n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    " \n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    " \n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    " \n",
    "batch_size = 100\n",
    "n_iters = 5000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    " \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    " \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    " \n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 300)\n",
    "        self.linear2 = nn.Linear(300, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "     \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.linear1(x))\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    " \n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    " \n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.9958114624023438. Accuracy: 71.9000015258789\n",
      "Iteration: 1000. Loss: 1.8346498012542725. Accuracy: 75.06999969482422\n",
      "Iteration: 1500. Loss: 1.6265698671340942. Accuracy: 76.76000213623047\n",
      "Iteration: 2000. Loss: 1.402841329574585. Accuracy: 78.31999969482422\n",
      "Iteration: 2500. Loss: 1.2652382850646973. Accuracy: 79.66000366210938\n",
      "Iteration: 3000. Loss: 1.2601224184036255. Accuracy: 80.97000122070312\n",
      "Iteration: 3500. Loss: 1.052241563796997. Accuracy: 82.19999694824219\n",
      "Iteration: 4000. Loss: 0.9773139357566833. Accuracy: 82.79000091552734\n",
      "Iteration: 4500. Loss: 0.9634380340576172. Accuracy: 83.75\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    " \n",
    "model.to(avDev)\n",
    " \n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss().to(avDev)\n",
    "\n",
    " \n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.001\n",
    " \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "         \n",
    "        #print(images.size()) #torch.Size([100, 1, 28, 28])\n",
    "        #print(images.view(-1, 28*28).size()) #torch.Size([100, 784])\n",
    "        images = images.view(-1, 28*28).to(avDev)\n",
    "        labels = labels.to(avDev)\n",
    "         \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "         \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)#\n",
    "         \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "         \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "         \n",
    "        iter += 1\n",
    "         \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = images.view(-1, 28*28).to(avDev)\n",
    "                 \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                 \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                 \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                 \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
    "             \n",
    "            accuracy = 100. * correct / total\n",
    "             \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 170090496/170498071 [00:37<00:00, 6267892.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import random as rand\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "trainset = dsets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = dsets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[1][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truck'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES[trainset[1][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "trainset[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8cb830dcc0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170500096it [00:50, 6267892.05it/s]                               "
     ]
    }
   ],
   "source": [
    "img = trainset[1][0]\n",
    "_to_pil = transforms.ToPILImage()\n",
    "\n",
    "print(img.shape)\n",
    "plt.imshow(_to_pil(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training a Logistic Regression Classifier with CIFAR-10 dataset using PyTorch\n",
    "- Draw learning curve and confusion matrix\n",
    "- Find the best hyperparameters\n",
    "- Plot gradient norm for each learnable parameter\n",
    "- Extra point:\n",
    "    - Use hyper-opt package to optimize two hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences:\n",
    "## https://www.pluralsight.com/ (Foundation to PyTorch class)\n",
    "## Pytorch Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
