{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment6.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/2kunal6/UniBonn/blob/master/cuda_lab/6/Assignment6.ipynb",
      "authorship_tag": "ABX9TyMip3pyYt5s3+rjZppWklqc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae2890698ba34751815a5eba5bfea904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f5474c038de843f99e8a3153e3dba2e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a9bee6353c8144ee95f272e5a9082c1c",
              "IPY_MODEL_4f7085cdb85441009c094cf637f3f41c"
            ]
          }
        },
        "f5474c038de843f99e8a3153e3dba2e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9bee6353c8144ee95f272e5a9082c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa0f583085774cf6a67a09e88423632d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb55c2c96a014f6ebf0ef877c3897829"
          }
        },
        "4f7085cdb85441009c094cf637f3f41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9f0501981e34a2eb9c1bf3cc969e234",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 31201172.00it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08daa060b9ba4574be55eadc1932d76d"
          }
        },
        "aa0f583085774cf6a67a09e88423632d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb55c2c96a014f6ebf0ef877c3897829": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9f0501981e34a2eb9c1bf3cc969e234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08daa060b9ba4574be55eadc1932d76d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2kunal6/UniBonn/blob/master/cuda_lab/6/Assignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrurRTQrYaWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFqrklQZX9Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adapted from lab session and https://github.com/coolvision/vae_conv/blob/master/vae_conv_model_mnist.py\n",
        "# Simple Convolutional Autoencoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils as utils\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UQ0qvbOYSbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "ae2890698ba34751815a5eba5bfea904",
            "f5474c038de843f99e8a3153e3dba2e9",
            "a9bee6353c8144ee95f272e5a9082c1c",
            "4f7085cdb85441009c094cf637f3f41c",
            "aa0f583085774cf6a67a09e88423632d",
            "bb55c2c96a014f6ebf0ef877c3897829",
            "b9f0501981e34a2eb9c1bf3cc969e234",
            "08daa060b9ba4574be55eadc1932d76d"
          ]
        },
        "outputId": "ffe353c5-dc76-409e-d328-9a91d3dba663"
      },
      "source": [
        "\n",
        "batch_size =100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Download Data\n",
        "\n",
        "cifar_train = dset.CIFAR10(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "cifar_test  = dset.CIFAR10(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "\n",
        "# Set Data Loader(input pipeline)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=cifar_train,batch_size=batch_size,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=cifar_train,batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae2890698ba34751815a5eba5bfea904",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed6-yHvzY4b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder \n",
        "# torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "#                 stride=1, padding=0, dilation=1,\n",
        "#                 groups=1, bias=True)\n",
        "# batch x 1 x 28 x 28 -> batch x 512\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "                        nn.Conv2d(3,32,3,padding=1),   # batch x 16 x 32 x 32\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,32,3,padding=1),   # batch x 16 x 32 x 32\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,64,3,padding=1),  # batch x 32 x 32 x 32\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Conv2d(64,64,3,padding=1),  # batch x 32 x 32 x 32\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.MaxPool2d(2,2)   # batch x 64 x 16 x 16\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "                        nn.ConvTranspose2d(64,128,3,2,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ConvTranspose2d(128,128,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ConvTranspose2d(128,64,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ConvTranspose2d(64,64,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64)\n",
        "        )\n",
        "        # encoder part\n",
        "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
        "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
        "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
        "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
        "        # decoder part\n",
        "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
        "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
        "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
        "                \n",
        "    def encoder(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
        "    \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu) # return z sample\n",
        "        \n",
        "    def decoder(self, z):\n",
        "        h = F.relu(self.fc4(z))\n",
        "        h = F.relu(self.fc5(h))\n",
        "        return F.sigmoid(self.fc6(h)) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encoder(x.view(-1, 3*32*32))\n",
        "        z = self.sampling(mu, log_var)\n",
        "        return self.decoder(z), mu, log_var\n",
        "    \n",
        "vae = VAE(x_dim=3*32*32, h_dim1= 512, h_dim2=256, z_dim=2)\n",
        "if torch.cuda.is_available():\n",
        "    vae.cuda()\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm1t4ziLbDRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(vae.parameters())\n",
        "# return reconstruction error + KL divergence losses\n",
        "def loss_function(recon_x, x, mu, log_var):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 3*32*32), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    return BCE + KLD"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8z5DwxTcj8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train encoder and decoder\n",
        "# save and load model\n",
        "\n",
        "def train(epoch):\n",
        "    vae.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        image_n = torch.mul(data+0.25, 0.1 * torch.rand(batch_size,3,32,32))\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            image_n = image_n.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        recon_batch, mu, log_var = vae(image_n)\n",
        "        loss = loss_function(recon_batch, data, mu, log_var)\n",
        "        \n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFzIzz8X22WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():    \n",
        "    vae.eval()\n",
        "    test_loss= 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "            recon, mu, log_var = vae(data)\n",
        "            \n",
        "            # sum up batch loss\n",
        "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
        "        \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfxUTChZsZvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "241ea9d0-1d97-4373-f2be-85f1966bd5f0"
      },
      "source": [
        "for epoch in range(1, 51):\n",
        "    train(epoch)\n",
        "    test()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1959.803281\n",
            "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 1991.072969\n",
            "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 1954.368750\n",
            "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 1945.870938\n",
            "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 1967.814219\n",
            "====> Epoch: 1 Average loss: 1961.0348\n",
            "====> Test set loss: 126515.6720\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1991.861094\n",
            "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 1987.834531\n",
            "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 1947.044688\n",
            "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 1970.370469\n",
            "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 1954.865625\n",
            "====> Epoch: 2 Average loss: 1959.7707\n",
            "====> Test set loss: 140575.9849\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1963.207969\n",
            "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 1973.168750\n",
            "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 1942.110000\n",
            "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 1974.874375\n",
            "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 1915.440625\n",
            "====> Epoch: 3 Average loss: 1959.1273\n",
            "====> Test set loss: 146455.8409\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1979.750000\n",
            "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 1944.925000\n",
            "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 1973.352344\n",
            "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 1973.701406\n",
            "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 1947.630781\n",
            "====> Epoch: 4 Average loss: 1958.5993\n",
            "====> Test set loss: 150826.7477\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1979.560469\n",
            "Train Epoch: 5 [10000/50000 (20%)]\tLoss: 1960.537031\n",
            "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 2001.346562\n",
            "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 1938.977187\n",
            "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 1989.770781\n",
            "====> Epoch: 5 Average loss: 1958.1814\n",
            "====> Test set loss: 154790.3865\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1980.979219\n",
            "Train Epoch: 6 [10000/50000 (20%)]\tLoss: 1971.483125\n",
            "Train Epoch: 6 [20000/50000 (40%)]\tLoss: 1967.843281\n",
            "Train Epoch: 6 [30000/50000 (60%)]\tLoss: 1950.695625\n",
            "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 1988.049844\n",
            "====> Epoch: 6 Average loss: 1957.8168\n",
            "====> Test set loss: 155407.2388\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1925.250937\n",
            "Train Epoch: 7 [10000/50000 (20%)]\tLoss: 1950.881562\n",
            "Train Epoch: 7 [20000/50000 (40%)]\tLoss: 1975.651875\n",
            "Train Epoch: 7 [30000/50000 (60%)]\tLoss: 1936.819375\n",
            "Train Epoch: 7 [40000/50000 (80%)]\tLoss: 1985.055156\n",
            "====> Epoch: 7 Average loss: 1957.6619\n",
            "====> Test set loss: 156715.3051\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1974.190312\n",
            "Train Epoch: 8 [10000/50000 (20%)]\tLoss: 1936.389062\n",
            "Train Epoch: 8 [20000/50000 (40%)]\tLoss: 1946.818125\n",
            "Train Epoch: 8 [30000/50000 (60%)]\tLoss: 1963.940469\n",
            "Train Epoch: 8 [40000/50000 (80%)]\tLoss: 1967.832969\n",
            "====> Epoch: 8 Average loss: 1957.1681\n",
            "====> Test set loss: 155475.2830\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1930.115000\n",
            "Train Epoch: 9 [10000/50000 (20%)]\tLoss: 1973.538906\n",
            "Train Epoch: 9 [20000/50000 (40%)]\tLoss: 1963.698437\n",
            "Train Epoch: 9 [30000/50000 (60%)]\tLoss: 1964.508125\n",
            "Train Epoch: 9 [40000/50000 (80%)]\tLoss: 1997.805312\n",
            "====> Epoch: 9 Average loss: 1956.4334\n",
            "====> Test set loss: 157021.6066\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1981.779687\n",
            "Train Epoch: 10 [10000/50000 (20%)]\tLoss: 1933.155000\n",
            "Train Epoch: 10 [20000/50000 (40%)]\tLoss: 1924.465469\n",
            "Train Epoch: 10 [30000/50000 (60%)]\tLoss: 1943.964062\n",
            "Train Epoch: 10 [40000/50000 (80%)]\tLoss: 1980.191875\n",
            "====> Epoch: 10 Average loss: 1955.0382\n",
            "====> Test set loss: 155806.0547\n",
            "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1957.688906\n",
            "Train Epoch: 11 [10000/50000 (20%)]\tLoss: 1945.861406\n",
            "Train Epoch: 11 [20000/50000 (40%)]\tLoss: 1984.806406\n",
            "Train Epoch: 11 [30000/50000 (60%)]\tLoss: 1955.023906\n",
            "Train Epoch: 11 [40000/50000 (80%)]\tLoss: 1959.840938\n",
            "====> Epoch: 11 Average loss: 1952.8465\n",
            "====> Test set loss: 155796.8429\n",
            "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1964.382188\n",
            "Train Epoch: 12 [10000/50000 (20%)]\tLoss: 1937.917031\n",
            "Train Epoch: 12 [20000/50000 (40%)]\tLoss: 1961.879531\n",
            "Train Epoch: 12 [30000/50000 (60%)]\tLoss: 1925.721406\n",
            "Train Epoch: 12 [40000/50000 (80%)]\tLoss: 1988.492344\n",
            "====> Epoch: 12 Average loss: 1950.6825\n",
            "====> Test set loss: 166269.1173\n",
            "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1997.418594\n",
            "Train Epoch: 13 [10000/50000 (20%)]\tLoss: 1951.082031\n",
            "Train Epoch: 13 [20000/50000 (40%)]\tLoss: 1901.681719\n",
            "Train Epoch: 13 [30000/50000 (60%)]\tLoss: 1966.500469\n",
            "Train Epoch: 13 [40000/50000 (80%)]\tLoss: 1915.296719\n",
            "====> Epoch: 13 Average loss: 1950.0227\n",
            "====> Test set loss: 32336898714.3812\n",
            "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1935.567656\n",
            "Train Epoch: 14 [10000/50000 (20%)]\tLoss: 1930.502500\n",
            "Train Epoch: 14 [20000/50000 (40%)]\tLoss: 1970.901094\n",
            "Train Epoch: 14 [30000/50000 (60%)]\tLoss: 1932.279063\n",
            "Train Epoch: 14 [40000/50000 (80%)]\tLoss: 1958.460313\n",
            "====> Epoch: 14 Average loss: 1948.7141\n",
            "====> Test set loss: 209900.7873\n",
            "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1985.652344\n",
            "Train Epoch: 15 [10000/50000 (20%)]\tLoss: 1941.504688\n",
            "Train Epoch: 15 [20000/50000 (40%)]\tLoss: 1938.336875\n",
            "Train Epoch: 15 [30000/50000 (60%)]\tLoss: 1939.228594\n",
            "Train Epoch: 15 [40000/50000 (80%)]\tLoss: 1968.427500\n",
            "====> Epoch: 15 Average loss: 1948.1686\n",
            "====> Test set loss: 5406150.2637\n",
            "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1950.593281\n",
            "Train Epoch: 16 [10000/50000 (20%)]\tLoss: 1950.395000\n",
            "Train Epoch: 16 [20000/50000 (40%)]\tLoss: 1934.444688\n",
            "Train Epoch: 16 [30000/50000 (60%)]\tLoss: 1957.461406\n",
            "Train Epoch: 16 [40000/50000 (80%)]\tLoss: 1932.988281\n",
            "====> Epoch: 16 Average loss: 1948.4871\n",
            "====> Test set loss: 5246803988.4663\n",
            "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1948.772344\n",
            "Train Epoch: 17 [10000/50000 (20%)]\tLoss: 1947.417344\n",
            "Train Epoch: 17 [20000/50000 (40%)]\tLoss: 1955.666094\n",
            "Train Epoch: 17 [30000/50000 (60%)]\tLoss: 1960.505312\n",
            "Train Epoch: 17 [40000/50000 (80%)]\tLoss: 1951.680312\n",
            "====> Epoch: 17 Average loss: 1948.6481\n",
            "====> Test set loss: 32644228.2506\n",
            "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1931.242500\n",
            "Train Epoch: 18 [10000/50000 (20%)]\tLoss: 1960.724688\n",
            "Train Epoch: 18 [20000/50000 (40%)]\tLoss: 1938.424531\n",
            "Train Epoch: 18 [30000/50000 (60%)]\tLoss: 1976.997188\n",
            "Train Epoch: 18 [40000/50000 (80%)]\tLoss: 1942.347500\n",
            "====> Epoch: 18 Average loss: 1948.3694\n",
            "====> Test set loss: 5597675826581.7471\n",
            "Train Epoch: 19 [0/50000 (0%)]\tLoss: 1947.163438\n",
            "Train Epoch: 19 [10000/50000 (20%)]\tLoss: 1931.615625\n",
            "Train Epoch: 19 [20000/50000 (40%)]\tLoss: 1942.945312\n",
            "Train Epoch: 19 [30000/50000 (60%)]\tLoss: 1922.359375\n",
            "Train Epoch: 19 [40000/50000 (80%)]\tLoss: 1914.770313\n",
            "====> Epoch: 19 Average loss: 1945.7790\n",
            "====> Test set loss: 6045786457318.2051\n",
            "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1965.069062\n",
            "Train Epoch: 20 [10000/50000 (20%)]\tLoss: 1941.297344\n",
            "Train Epoch: 20 [20000/50000 (40%)]\tLoss: 1941.551094\n",
            "Train Epoch: 20 [30000/50000 (60%)]\tLoss: 1933.331250\n",
            "Train Epoch: 20 [40000/50000 (80%)]\tLoss: 1909.170156\n",
            "====> Epoch: 20 Average loss: 1946.7646\n",
            "====> Test set loss: 13138463.7371\n",
            "Train Epoch: 21 [0/50000 (0%)]\tLoss: 1968.556719\n",
            "Train Epoch: 21 [10000/50000 (20%)]\tLoss: 1905.021719\n",
            "Train Epoch: 21 [20000/50000 (40%)]\tLoss: 1937.050781\n",
            "Train Epoch: 21 [30000/50000 (60%)]\tLoss: 1970.265938\n",
            "Train Epoch: 21 [40000/50000 (80%)]\tLoss: 1963.281719\n",
            "====> Epoch: 21 Average loss: 1947.4741\n",
            "====> Test set loss: 22814856470.3431\n",
            "Train Epoch: 22 [0/50000 (0%)]\tLoss: 1928.369219\n",
            "Train Epoch: 22 [10000/50000 (20%)]\tLoss: 1896.895313\n",
            "Train Epoch: 22 [20000/50000 (40%)]\tLoss: 1909.480625\n",
            "Train Epoch: 22 [30000/50000 (60%)]\tLoss: 1972.383906\n",
            "Train Epoch: 22 [40000/50000 (80%)]\tLoss: 1957.188750\n",
            "====> Epoch: 22 Average loss: 1948.6756\n",
            "====> Test set loss: 159962.3726\n",
            "Train Epoch: 23 [0/50000 (0%)]\tLoss: 1948.746562\n",
            "Train Epoch: 23 [10000/50000 (20%)]\tLoss: 1944.278125\n",
            "Train Epoch: 23 [20000/50000 (40%)]\tLoss: 1958.356406\n",
            "Train Epoch: 23 [30000/50000 (60%)]\tLoss: 1935.517969\n",
            "Train Epoch: 23 [40000/50000 (80%)]\tLoss: 1935.895937\n",
            "====> Epoch: 23 Average loss: 1944.7071\n",
            "====> Test set loss: 1508997.7282\n",
            "Train Epoch: 24 [0/50000 (0%)]\tLoss: 1930.372031\n",
            "Train Epoch: 24 [10000/50000 (20%)]\tLoss: 1932.260937\n",
            "Train Epoch: 24 [20000/50000 (40%)]\tLoss: 1926.308438\n",
            "Train Epoch: 24 [30000/50000 (60%)]\tLoss: 1950.150938\n",
            "Train Epoch: 24 [40000/50000 (80%)]\tLoss: 1956.443281\n",
            "====> Epoch: 24 Average loss: 1947.0514\n",
            "====> Test set loss: 150741.9091\n",
            "Train Epoch: 25 [0/50000 (0%)]\tLoss: 1970.603437\n",
            "Train Epoch: 25 [10000/50000 (20%)]\tLoss: 1945.030156\n",
            "Train Epoch: 25 [20000/50000 (40%)]\tLoss: 1915.009844\n",
            "Train Epoch: 25 [30000/50000 (60%)]\tLoss: 1950.137187\n",
            "Train Epoch: 25 [40000/50000 (80%)]\tLoss: 1955.865625\n",
            "====> Epoch: 25 Average loss: 1946.1435\n",
            "====> Test set loss: 151953.7031\n",
            "Train Epoch: 26 [0/50000 (0%)]\tLoss: 1946.141250\n",
            "Train Epoch: 26 [10000/50000 (20%)]\tLoss: 1978.589531\n",
            "Train Epoch: 26 [20000/50000 (40%)]\tLoss: 1955.106250\n",
            "Train Epoch: 26 [30000/50000 (60%)]\tLoss: 1948.116719\n",
            "Train Epoch: 26 [40000/50000 (80%)]\tLoss: 1967.773750\n",
            "====> Epoch: 26 Average loss: 1947.6833\n",
            "====> Test set loss: 151285.9268\n",
            "Train Epoch: 27 [0/50000 (0%)]\tLoss: 1958.369375\n",
            "Train Epoch: 27 [10000/50000 (20%)]\tLoss: 1973.931875\n",
            "Train Epoch: 27 [20000/50000 (40%)]\tLoss: 1948.950156\n",
            "Train Epoch: 27 [30000/50000 (60%)]\tLoss: 1967.997656\n",
            "Train Epoch: 27 [40000/50000 (80%)]\tLoss: 1946.828594\n",
            "====> Epoch: 27 Average loss: 1947.3393\n",
            "====> Test set loss: 290276.3505\n",
            "Train Epoch: 28 [0/50000 (0%)]\tLoss: 1950.733594\n",
            "Train Epoch: 28 [10000/50000 (20%)]\tLoss: 1926.822813\n",
            "Train Epoch: 28 [20000/50000 (40%)]\tLoss: 1962.355937\n",
            "Train Epoch: 28 [30000/50000 (60%)]\tLoss: 1924.732344\n",
            "Train Epoch: 28 [40000/50000 (80%)]\tLoss: 1957.169375\n",
            "====> Epoch: 28 Average loss: 1947.2402\n",
            "====> Test set loss: 149027.3066\n",
            "Train Epoch: 29 [0/50000 (0%)]\tLoss: 1911.228281\n",
            "Train Epoch: 29 [10000/50000 (20%)]\tLoss: 1927.828438\n",
            "Train Epoch: 29 [20000/50000 (40%)]\tLoss: 1935.858281\n",
            "Train Epoch: 29 [30000/50000 (60%)]\tLoss: 1953.747344\n",
            "Train Epoch: 29 [40000/50000 (80%)]\tLoss: 1992.248750\n",
            "====> Epoch: 29 Average loss: 1950.2638\n",
            "====> Test set loss: 146374.1796\n",
            "Train Epoch: 30 [0/50000 (0%)]\tLoss: 1955.081563\n",
            "Train Epoch: 30 [10000/50000 (20%)]\tLoss: 1958.840000\n",
            "Train Epoch: 30 [20000/50000 (40%)]\tLoss: 1955.836250\n",
            "Train Epoch: 30 [30000/50000 (60%)]\tLoss: 1933.132344\n",
            "Train Epoch: 30 [40000/50000 (80%)]\tLoss: 1970.893281\n",
            "====> Epoch: 30 Average loss: 1946.0201\n",
            "====> Test set loss: 152293.1759\n",
            "Train Epoch: 31 [0/50000 (0%)]\tLoss: 1940.833594\n",
            "Train Epoch: 31 [10000/50000 (20%)]\tLoss: 1990.940156\n",
            "Train Epoch: 31 [20000/50000 (40%)]\tLoss: 1932.587812\n",
            "Train Epoch: 31 [30000/50000 (60%)]\tLoss: 1944.910156\n",
            "Train Epoch: 31 [40000/50000 (80%)]\tLoss: 1929.824219\n",
            "====> Epoch: 31 Average loss: 1944.6616\n",
            "====> Test set loss: 154790.0650\n",
            "Train Epoch: 32 [0/50000 (0%)]\tLoss: 1954.780625\n",
            "Train Epoch: 32 [10000/50000 (20%)]\tLoss: 1949.263906\n",
            "Train Epoch: 32 [20000/50000 (40%)]\tLoss: 1943.880312\n",
            "Train Epoch: 32 [30000/50000 (60%)]\tLoss: 1932.596719\n",
            "Train Epoch: 32 [40000/50000 (80%)]\tLoss: 1924.917969\n",
            "====> Epoch: 32 Average loss: 1949.8794\n",
            "====> Test set loss: 155619.2965\n",
            "Train Epoch: 33 [0/50000 (0%)]\tLoss: 1949.013594\n",
            "Train Epoch: 33 [10000/50000 (20%)]\tLoss: 1963.078125\n",
            "Train Epoch: 33 [20000/50000 (40%)]\tLoss: 1952.301094\n",
            "Train Epoch: 33 [30000/50000 (60%)]\tLoss: 1917.541719\n",
            "Train Epoch: 33 [40000/50000 (80%)]\tLoss: 1952.125469\n",
            "====> Epoch: 33 Average loss: 1949.4982\n",
            "====> Test set loss: 154052.5554\n",
            "Train Epoch: 34 [0/50000 (0%)]\tLoss: 1985.996406\n",
            "Train Epoch: 34 [10000/50000 (20%)]\tLoss: 1939.677500\n",
            "Train Epoch: 34 [20000/50000 (40%)]\tLoss: 1912.156719\n",
            "Train Epoch: 34 [30000/50000 (60%)]\tLoss: 1944.187500\n",
            "Train Epoch: 34 [40000/50000 (80%)]\tLoss: 1958.005312\n",
            "====> Epoch: 34 Average loss: 1948.2135\n",
            "====> Test set loss: 152646.3322\n",
            "Train Epoch: 35 [0/50000 (0%)]\tLoss: 1955.614219\n",
            "Train Epoch: 35 [10000/50000 (20%)]\tLoss: 1948.723281\n",
            "Train Epoch: 35 [20000/50000 (40%)]\tLoss: 1979.377187\n",
            "Train Epoch: 35 [30000/50000 (60%)]\tLoss: 1975.585469\n",
            "Train Epoch: 35 [40000/50000 (80%)]\tLoss: 1981.378594\n",
            "====> Epoch: 35 Average loss: 1948.7274\n",
            "====> Test set loss: 37445713166.6962\n",
            "Train Epoch: 36 [0/50000 (0%)]\tLoss: 1963.518594\n",
            "Train Epoch: 36 [10000/50000 (20%)]\tLoss: 1961.669375\n",
            "Train Epoch: 36 [20000/50000 (40%)]\tLoss: 1948.166094\n",
            "Train Epoch: 36 [30000/50000 (60%)]\tLoss: 1957.908906\n",
            "Train Epoch: 36 [40000/50000 (80%)]\tLoss: 1969.742812\n",
            "====> Epoch: 36 Average loss: 1949.5317\n",
            "====> Test set loss: 2249628642075746956679839744.0000\n",
            "Train Epoch: 37 [0/50000 (0%)]\tLoss: 1933.103437\n",
            "Train Epoch: 37 [10000/50000 (20%)]\tLoss: 1957.234531\n",
            "Train Epoch: 37 [20000/50000 (40%)]\tLoss: 1963.425156\n",
            "Train Epoch: 37 [30000/50000 (60%)]\tLoss: 1966.369219\n",
            "Train Epoch: 37 [40000/50000 (80%)]\tLoss: 1984.045781\n",
            "====> Epoch: 37 Average loss: 1949.7141\n",
            "====> Test set loss: 153167.3392\n",
            "Train Epoch: 38 [0/50000 (0%)]\tLoss: 1970.877187\n",
            "Train Epoch: 38 [10000/50000 (20%)]\tLoss: 1955.044375\n",
            "Train Epoch: 38 [20000/50000 (40%)]\tLoss: 1961.731094\n",
            "Train Epoch: 38 [30000/50000 (60%)]\tLoss: 1922.291250\n",
            "Train Epoch: 38 [40000/50000 (80%)]\tLoss: 1947.116875\n",
            "====> Epoch: 38 Average loss: 1949.2364\n",
            "====> Test set loss: 154439.9797\n",
            "Train Epoch: 39 [0/50000 (0%)]\tLoss: 1945.036406\n",
            "Train Epoch: 39 [10000/50000 (20%)]\tLoss: 1943.775781\n",
            "Train Epoch: 39 [20000/50000 (40%)]\tLoss: 1931.155156\n",
            "Train Epoch: 39 [30000/50000 (60%)]\tLoss: 1973.524219\n",
            "Train Epoch: 39 [40000/50000 (80%)]\tLoss: 1949.821875\n",
            "====> Epoch: 39 Average loss: 1947.4699\n",
            "====> Test set loss: 153592.3357\n",
            "Train Epoch: 40 [0/50000 (0%)]\tLoss: 1894.982344\n",
            "Train Epoch: 40 [10000/50000 (20%)]\tLoss: 1964.326406\n",
            "Train Epoch: 40 [20000/50000 (40%)]\tLoss: 1948.863594\n",
            "Train Epoch: 40 [30000/50000 (60%)]\tLoss: 1952.416094\n",
            "Train Epoch: 40 [40000/50000 (80%)]\tLoss: 1969.269063\n",
            "====> Epoch: 40 Average loss: 1947.2905\n",
            "====> Test set loss: 153875.5464\n",
            "Train Epoch: 41 [0/50000 (0%)]\tLoss: 1956.716406\n",
            "Train Epoch: 41 [10000/50000 (20%)]\tLoss: 1946.610312\n",
            "Train Epoch: 41 [20000/50000 (40%)]\tLoss: 1953.919688\n",
            "Train Epoch: 41 [30000/50000 (60%)]\tLoss: 1945.451406\n",
            "Train Epoch: 41 [40000/50000 (80%)]\tLoss: 1967.678125\n",
            "====> Epoch: 41 Average loss: 1946.1621\n",
            "====> Test set loss: 152818.1970\n",
            "Train Epoch: 42 [0/50000 (0%)]\tLoss: 1936.391250\n",
            "Train Epoch: 42 [10000/50000 (20%)]\tLoss: 1939.680938\n",
            "Train Epoch: 42 [20000/50000 (40%)]\tLoss: 1943.350938\n",
            "Train Epoch: 42 [30000/50000 (60%)]\tLoss: 1947.121406\n",
            "Train Epoch: 42 [40000/50000 (80%)]\tLoss: 1937.561719\n",
            "====> Epoch: 42 Average loss: 1944.2738\n",
            "====> Test set loss: 153149.5263\n",
            "Train Epoch: 43 [0/50000 (0%)]\tLoss: 1942.381250\n",
            "Train Epoch: 43 [10000/50000 (20%)]\tLoss: 1979.920625\n",
            "Train Epoch: 43 [20000/50000 (40%)]\tLoss: 1973.076719\n",
            "Train Epoch: 43 [30000/50000 (60%)]\tLoss: 1943.615781\n",
            "Train Epoch: 43 [40000/50000 (80%)]\tLoss: 1907.987500\n",
            "====> Epoch: 43 Average loss: 1947.7090\n",
            "====> Test set loss: 96672393233327888.0000\n",
            "Train Epoch: 44 [0/50000 (0%)]\tLoss: 1943.222969\n",
            "Train Epoch: 44 [10000/50000 (20%)]\tLoss: 1914.489219\n",
            "Train Epoch: 44 [20000/50000 (40%)]\tLoss: 1917.432188\n",
            "Train Epoch: 44 [30000/50000 (60%)]\tLoss: 1952.243750\n",
            "Train Epoch: 44 [40000/50000 (80%)]\tLoss: 1909.426250\n",
            "====> Epoch: 44 Average loss: 1944.7477\n",
            "====> Test set loss: 59505559594122.5703\n",
            "Train Epoch: 45 [0/50000 (0%)]\tLoss: 1968.258594\n",
            "Train Epoch: 45 [10000/50000 (20%)]\tLoss: 1935.678594\n",
            "Train Epoch: 45 [20000/50000 (40%)]\tLoss: 1930.875156\n",
            "Train Epoch: 45 [30000/50000 (60%)]\tLoss: 1947.179375\n",
            "Train Epoch: 45 [40000/50000 (80%)]\tLoss: 1942.137656\n",
            "====> Epoch: 45 Average loss: 1945.8581\n",
            "====> Test set loss: 78999471.9294\n",
            "Train Epoch: 46 [0/50000 (0%)]\tLoss: 1941.124531\n",
            "Train Epoch: 46 [10000/50000 (20%)]\tLoss: 1944.192188\n",
            "Train Epoch: 46 [20000/50000 (40%)]\tLoss: 1930.307812\n",
            "Train Epoch: 46 [30000/50000 (60%)]\tLoss: 1932.956094\n",
            "Train Epoch: 46 [40000/50000 (80%)]\tLoss: 1943.386719\n",
            "====> Epoch: 46 Average loss: 1945.1130\n",
            "====> Test set loss: 154158.9564\n",
            "Train Epoch: 47 [0/50000 (0%)]\tLoss: 1962.747188\n",
            "Train Epoch: 47 [10000/50000 (20%)]\tLoss: 1949.296562\n",
            "Train Epoch: 47 [20000/50000 (40%)]\tLoss: 1963.755312\n",
            "Train Epoch: 47 [30000/50000 (60%)]\tLoss: 1965.318281\n",
            "Train Epoch: 47 [40000/50000 (80%)]\tLoss: 1978.609688\n",
            "====> Epoch: 47 Average loss: 1943.2661\n",
            "====> Test set loss: 151973.8574\n",
            "Train Epoch: 48 [0/50000 (0%)]\tLoss: 1924.073437\n",
            "Train Epoch: 48 [10000/50000 (20%)]\tLoss: 1946.573906\n",
            "Train Epoch: 48 [20000/50000 (40%)]\tLoss: 1933.171875\n",
            "Train Epoch: 48 [30000/50000 (60%)]\tLoss: 1938.699531\n",
            "Train Epoch: 48 [40000/50000 (80%)]\tLoss: 1940.026719\n",
            "====> Epoch: 48 Average loss: 1943.9682\n",
            "====> Test set loss: 152140.4330\n",
            "Train Epoch: 49 [0/50000 (0%)]\tLoss: 1967.977813\n",
            "Train Epoch: 49 [10000/50000 (20%)]\tLoss: 1919.096562\n",
            "Train Epoch: 49 [20000/50000 (40%)]\tLoss: 1904.729687\n",
            "Train Epoch: 49 [30000/50000 (60%)]\tLoss: 1919.658906\n",
            "Train Epoch: 49 [40000/50000 (80%)]\tLoss: 1915.872656\n",
            "====> Epoch: 49 Average loss: 1944.9145\n",
            "====> Test set loss: 154312.8995\n",
            "Train Epoch: 50 [0/50000 (0%)]\tLoss: 1961.284844\n",
            "Train Epoch: 50 [10000/50000 (20%)]\tLoss: 1949.047031\n",
            "Train Epoch: 50 [20000/50000 (40%)]\tLoss: 1931.407187\n",
            "Train Epoch: 50 [30000/50000 (60%)]\tLoss: 1946.492344\n",
            "Train Epoch: 50 [40000/50000 (80%)]\tLoss: 1949.354063\n",
            "====> Epoch: 50 Average loss: 1946.1748\n",
            "====> Test set loss: 155104.3422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l0NltIXcnGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = 'drive/My Drive/colab_data/cuda_lab/6/vae.pth'\n",
        "torch.save(vae.state_dict(), PATH)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgOKeoaIAAsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    \n",
        "vae = VAE(x_dim=3*32*32, h_dim1= 512, h_dim2=256, z_dim=2)\n",
        "vae.load_state_dict(torch.load(PATH))\n",
        "if torch.cuda.is_available():\n",
        "  vae.cuda()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gh7QTcwAwcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}