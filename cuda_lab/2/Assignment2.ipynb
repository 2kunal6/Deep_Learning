{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2kunal6/UniBonn/blob/master/cuda_lab/2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eaf9IZKR0EN4",
        "colab_type": "code",
        "outputId": "ae64c8e3-7d0a-4983-f235-34b5a3a7f98d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "transform_list = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=1),\n",
        "            transforms.ToTensor()\n",
        "            #transforms.Normalize([0.5,],[0.5,])\n",
        "        ])\n",
        "train = datasets.CIFAR10(\"./\", train=True, transform=transform_list, download=True)\n",
        "\n",
        "test = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(\"./\", train=False, transform=transform_list, download=True), batch_size = 32, shuffle = True\n",
        ")\n",
        "\n",
        "print(\"datasets loaded\")\n",
        "\n",
        "IMG_SIZE = 32*32\n",
        "\n",
        "'''for data in train:\n",
        "  X, y = data[0][0], data[1][0]\n",
        "  plt.imshow(X.view(32, 32))\n",
        "  print(\"Label: \" + str(y))\n",
        "  plt.show()\n",
        "  break'''\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")\n",
        "\n",
        "model = LogisticRegression(IMG_SIZE, 10).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(2):\n",
        "  train_size = int(0.9 * len(train))\n",
        "  val_size = len(train) - train_size\n",
        "  train_dataset, val_dataset = torch.utils.data.random_split(train, [train_size, val_size])\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = 32, shuffle = True)\n",
        "  for data in train_loader:\n",
        "    X, y = data[0].to(device), data[1].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X.view(-1, IMG_SIZE))\n",
        "    loss = F.cross_entropy(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f'epoch: {epoch}, loss: {loss}')\n",
        "\n",
        "def test_perform():\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "  with torch.no_grad():\n",
        "    for data in test:\n",
        "      X, y = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      output = model(X.view(-1, IMG_SIZE))\n",
        "      _, predicted = torch.max(output, 1)\n",
        "\n",
        "      total += y.size(0)\n",
        "      correct += (predicted == y).sum().item()\n",
        "\n",
        "      y_pred.extend(predicted.tolist())\n",
        "      y_true.extend(y.tolist())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy, y_true, y_pred\n",
        "    \n",
        "accuracy, y_true, y_pred = test_perform()\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(f'Accuracy of the network on the 10000 test images: {accuracy}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "datasets loaded\n",
            "Running on the GPU\n",
            "epoch: 0, loss: 3.834385871887207\n",
            "epoch: 1, loss: 2.5606110095977783\n",
            "[[  0   2 853   3   1   9  12   0  16 104]\n",
            " [  0  49 495   4   7  23  22   0  27 373]\n",
            " [  0   2 876   5   4  45  24   0   2  42]\n",
            " [  0   6 724  26   5 122  23   0   7  87]\n",
            " [  0   2 865   6  10  50  12   0   2  53]\n",
            " [  0   1 691  11   1 224  14   0   8  50]\n",
            " [  0   3 767   8   8  69  55   0   5  85]\n",
            " [  0   0 801   2   4  56   8   0   9 120]\n",
            " [  0   5 697   3   0  30   7   0  65 193]\n",
            " [  0   7 381   3   4  17  16   0  27 545]]\n",
            "Accuracy of the network on the 10000 test images: 18.5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}