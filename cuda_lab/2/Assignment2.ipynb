{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2kunal6/UniBonn/blob/master/cuda_lab/2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eaf9IZKR0EN4",
        "colab_type": "code",
        "outputId": "53881a14-96af-4d7e-dc7f-4404bbdd470c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "transform_list = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=1),\n",
        "            transforms.ToTensor()\n",
        "            #transforms.Normalize([0.5,],[0.5,])\n",
        "        ])\n",
        "train = datasets.CIFAR10(\"./\", train=True, transform=transform_list, download=True)\n",
        "\n",
        "test = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(\"./\", train=False, transform=transform_list, download=True), batch_size = 32, shuffle = True\n",
        ")\n",
        "\n",
        "print(\"datasets loaded\")\n",
        "\n",
        "IMG_SIZE = 32*32\n",
        "\n",
        "'''for data in train:\n",
        "  X, y = data[0][0], data[1][0]\n",
        "  plt.imshow(X.view(32, 32))\n",
        "  print(\"Label: \" + str(y))\n",
        "  plt.show()\n",
        "  break'''\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, 300)\n",
        "    self.linear2 = nn.Linear(300, output_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.relu(self.linear1(x))\n",
        "    out = self.linear2(out)\n",
        "    return out\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")\n",
        "\n",
        "model = LogisticRegression(IMG_SIZE, 10).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "def test_perform(test_data):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "  with torch.no_grad():\n",
        "    for data in test_data:\n",
        "      X, y = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      output = model(X.view(-1, IMG_SIZE))\n",
        "      _, predicted = torch.max(output, 1)\n",
        "\n",
        "      total += y.size(0)\n",
        "      correct += (predicted == y).sum().item()\n",
        "\n",
        "      y_pred.extend(predicted.tolist())\n",
        "      y_true.extend(y.tolist())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy, y_true, y_pred\n",
        "\n",
        "\n",
        "for epoch in range(20):\n",
        "  train_size = int(0.9 * len(train))\n",
        "  val_size = len(train) - train_size\n",
        "  train_dataset, val_dataset = torch.utils.data.random_split(train, [train_size, val_size])\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = 32, shuffle = True)\n",
        "  for data in train_loader:\n",
        "    X, y = data[0].to(device), data[1].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X.view(-1, IMG_SIZE))\n",
        "    loss = criterion(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f'epoch: {epoch}, loss: {loss}')\n",
        "\n",
        "    \n",
        "accuracy, y_true, y_pred = test_perform(test)\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(f'Accuracy of the network on the 10000 test images: {accuracy}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "datasets loaded\n",
            "Running on the GPU\n",
            "epoch: 0, loss: 2.2840306758880615\n",
            "epoch: 1, loss: 2.0513477325439453\n",
            "epoch: 2, loss: 2.186150550842285\n",
            "epoch: 3, loss: 2.3392558097839355\n",
            "epoch: 4, loss: 2.489842414855957\n",
            "epoch: 5, loss: 2.0354650020599365\n",
            "epoch: 6, loss: 1.5546187162399292\n",
            "epoch: 7, loss: 1.9133005142211914\n",
            "epoch: 8, loss: 2.123992681503296\n",
            "epoch: 9, loss: 2.41884446144104\n",
            "epoch: 10, loss: 1.9515855312347412\n",
            "epoch: 11, loss: 2.1631078720092773\n",
            "epoch: 12, loss: 2.29356050491333\n",
            "epoch: 13, loss: 1.825661063194275\n",
            "epoch: 14, loss: 2.166281223297119\n",
            "epoch: 15, loss: 2.1993050575256348\n",
            "epoch: 16, loss: 1.7991697788238525\n",
            "epoch: 17, loss: 2.2662792205810547\n",
            "epoch: 18, loss: 2.0974225997924805\n",
            "epoch: 19, loss: 1.7113345861434937\n",
            "[[169 203   0  27 543   3   0   0   3  52]\n",
            " [120 371   0  31 173   3   0   0   2 300]\n",
            " [171  94   0  50 654  10   0   0   1  20]\n",
            " [144 145   0 167 457  55   0   1   6  25]\n",
            " [154 114   0  49 674   3   0   0   0   6]\n",
            " [110 115   0 187 450 119   0   0   8  11]\n",
            " [215 176   0 102 454  18   0   0  11  24]\n",
            " [163 162   0  47 584  12   0   0   0  32]\n",
            " [140 331   0  95 204  36   0   0   7 187]\n",
            " [122 345   0  19 127   3   0   0   4 380]]\n",
            "Accuracy of the network on the 10000 test images: 18.87\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}