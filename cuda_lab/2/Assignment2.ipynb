{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2kunal6/UniBonn/blob/master/cuda_lab/2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eaf9IZKR0EN4",
        "colab_type": "code",
        "outputId": "03d11288-93e2-40ed-ca8a-8105a8d43af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "transform_list = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5,],[0.5,])\n",
        "        ])\n",
        "train = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(\"./sample_data\", train=True, transform=transform_list, download=True), batch_size = 32, shuffle = True\n",
        ")\n",
        "\n",
        "test = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(\"./sample_data\", train=False, transform=transform_list, download=True), batch_size = 32, shuffle = True\n",
        ")\n",
        "\n",
        "print(\"datasets loaded\")\n",
        "\n",
        "IMG_SIZE = 32*32\n",
        "\n",
        "for data in train:\n",
        "  X, y = data[0], data[1]\n",
        "  #plt.imshow(X[0])\n",
        "  #print(\"Label: \" + str(y[0]))\n",
        "  #plt.show()\n",
        "  break\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")\n",
        "\n",
        "model = LogisticRegression(IMG_SIZE, 10).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(20):\n",
        "  for data in train:\n",
        "    X, y = data[0].to(device), data[1].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X.view(-1, IMG_SIZE))\n",
        "    loss = F.cross_entropy(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f'epoch: {epoch}, loss: {loss}')\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test:\n",
        "    X, y = data[0].to(device), data[1].to(device)\n",
        "    output = model(X.view(-1, IMG_SIZE))\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    total += y.size(0)\n",
        "    correct += (predicted == y).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "datasets loaded\n",
            "Running on the GPU\n",
            "epoch: 0, loss: 2.064054250717163\n",
            "epoch: 1, loss: 3.618572235107422\n",
            "epoch: 2, loss: 2.8538265228271484\n",
            "epoch: 3, loss: 2.2574737071990967\n",
            "epoch: 4, loss: 2.272906541824341\n",
            "epoch: 5, loss: 1.9147344827651978\n",
            "epoch: 6, loss: 2.237785577774048\n",
            "epoch: 7, loss: 3.054563283920288\n",
            "epoch: 8, loss: 2.49027681350708\n",
            "epoch: 9, loss: 2.8396451473236084\n",
            "epoch: 10, loss: 1.7107367515563965\n",
            "epoch: 11, loss: 2.2247610092163086\n",
            "epoch: 12, loss: 3.644300699234009\n",
            "epoch: 13, loss: 2.730564594268799\n",
            "epoch: 14, loss: 3.289738416671753\n",
            "epoch: 15, loss: 2.9807775020599365\n",
            "epoch: 16, loss: 2.134479522705078\n",
            "epoch: 17, loss: 3.254472017288208\n",
            "epoch: 18, loss: 2.8755292892456055\n",
            "epoch: 19, loss: 2.839099168777466\n",
            "Accuracy of the network on the 10000 test images: 21 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}