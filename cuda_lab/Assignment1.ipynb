{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKyYAVhZK/7eJ7yamSEFw/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2kunal6/UniBonn/blob/master/cuda_lab/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG7jhuOn3zeU",
        "colab_type": "code",
        "outputId": "9d382582-f391-45fc-9a37-3f489a991f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "train_mnist = datasets.MNIST(\"\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "test_mnist = datasets.MNIST(\"\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "train = []\n",
        "test = []\n",
        "for data in train_mnist:\n",
        "  train.append([data[0].view(28*28).numpy(), np.eye(10)[data[1]]])\n",
        "\n",
        "for data in test_mnist:\n",
        "  test.append([data[0].view(28*28).numpy(), np.eye(10)[data[1]]])\n",
        "\n",
        "\n",
        "print(len(train))\n",
        "print(len(test))\n",
        "print(len(train[0][0]), type(train[0][0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "10000\n",
            "784 <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaHrF1YEIXSQ",
        "colab_type": "code",
        "outputId": "925d3af0-bc87-429b-e228-31fc04651f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "num_input = 784\n",
        "num_output = 10\n",
        "weight = np.random.random((num_output, num_input))\n",
        "bias = 0.0\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "def forward(x, y):\n",
        "  x = data[0]\n",
        "  y = data[1]\n",
        "  net = [0] * num_output\n",
        "  for i in range(num_output):\n",
        "    for j in range(num_input):\n",
        "      net[i] += (x[j] * weight[i][j] + bias)\n",
        "  return softmax(net)\n",
        "\n",
        "# MSE\n",
        "def calc_loss(y, y_pred):\n",
        "  #print(y)\n",
        "  #print(y_pred)\n",
        "  return ((y-y_pred)**2).mean()\n",
        "\n",
        "# gradient of MSE dJ/dw = 1/N 2x (w*x - y)\n",
        "def calc_gradient(x, y, y_pred):\n",
        "  return (np.dot(2*x, y_pred - y)).mean()\n",
        "\n",
        "#print(\"prediction before training : \", forward(10))\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "for epoch in range(15):\n",
        "  BATCH_SIZE = 20 # without replacement\n",
        "  for data in train:\n",
        "    x, y = data[0], data[1]\n",
        "    y_pred = forward(x, y)\n",
        "    #print(sum(y_pred))\n",
        "    loss = calc_loss(y, y_pred)\n",
        "\n",
        "    grad = calc_gradient(x, y, y_pred)\n",
        "    break\n",
        "\n",
        "  w -= learning_rate * grad\n",
        "\n",
        "  print(\"epoch : \", epoch, \"weight : \", w, \"loss : \", loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9c786db3986a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-9c786db3986a>\u001b[0m in \u001b[0;36mcalc_gradient\u001b[0;34m(x, y, y_pred)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# gradient of MSE dJ/dw = 1/N 2x (w*x - y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#print(\"prediction before training : \", forward(10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (784,) and (10,) not aligned: 784 (dim 0) != 10 (dim 0)"
          ]
        }
      ]
    }
  ]
}